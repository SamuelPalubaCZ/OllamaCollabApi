{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SamuelPalubaCZ/OllamaCollabApi/blob/main/main.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sk0QyUSuP-f2"
      },
      "source": [
        "<h2><hr>Do toho to listu zapište prosím modely které chcete stáhnout\n",
        "</h2> <h5>Pokud nemáš nejmenší tušení koukni se do komentáře nebo na obrázek </h5>\n",
        "<img title=\"List of models Ollama 2024\" src=\"https://miro.medium.com/v2/resize:fit:1362/1*36VW4LFnORnqR1mZ_Rrazw.png\">\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "85-xEtaCM8Kt"
      },
      "outputs": [],
      "source": [
        "#list_of_models = ['llama3.2','dolphin-llama3','UnknownFish/waltergpt','yantien/gemma2-uncensored','llama3.1:70b','monotykamary/medichat-llama3']\n",
        "#example\n",
        "list_of_models = ['mistral']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QMSvdvBLQymp"
      },
      "source": [
        "<br>\n",
        "<h2>**Metoda 1. ** Doporučeno</h2>\n",
        "<hr><h3>Skript od uživatele [SamuelPalubaCZ](https://github.com/SamuelPalubaCZ/)</hr></h3>\n",
        "\n",
        "\n",
        "*   Rozjede Ollamu s Veřejnou ip a api pomocí Cloudflared a najtes to potom na doméně [https://api.paluba.me](https://api.paluba.me)\n",
        "*   Nevyžaduje daší setup\n",
        "*   Spolehlivé\n",
        "*   Vhodné pro komerční využití"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKQfQQSiXiJA"
      },
      "source": [
        "<hr>\n",
        "<H3>Instalační Skript:</h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iAl_LLX_GVrK"
      },
      "outputs": [],
      "source": [
        "!sudo apt-get install -y lspci libuv1 lshw pciutils cuda-drivers\n",
        "import os\n",
        "#check if ollama installed and if not install it\n",
        "os.environ.update({'LD_LIBRARY_PATH': '/usr/lib64-nvidia'})\n",
        "!curl https://ollama.ai/install.sh | sh\n",
        "!wget https://github.com/cloudflare/cloudflared/releases/latest/download/cloudflared-linux-amd64.deb\n",
        "!dpkg -i cloudflared-linux-amd64.deb\n",
        "\n",
        "import threading\n",
        "import subprocess\n",
        "import requests\n",
        "import time\n",
        "import socket\n",
        "\n",
        "os.environ.update({'OLLAMA_HOST': '0.0.0.0'})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "K1IupsyGMT1k"
      },
      "outputs": [],
      "source": [
        "def ollama(host='0.0.0.0:11434',origins='*',keepalive='-1'):\n",
        "    os.environ['OLLAMA_HOST'] = host\n",
        "    os.environ['OLLAMA_ORIGINS'] = origins\n",
        "    os.environ['OLLAMA_KEEP_ALIVE'] = keepalive\n",
        "    subprocess.Popen([\"ollama\", \"serve\"])\n",
        "    print(\"Ollama server started\")\n",
        "ollama_thread = threading.Thread(target=ollama)\n",
        "\n",
        "def install_models(lii=list_of_models):\n",
        "  for liu in lii:\n",
        "    !ollama pull {liu}\n",
        "  print(\"Models installed\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "REE9LZXiRRPN"
      },
      "source": [
        "<hr>\n",
        "<h3>\n",
        "Iniciační skripta:\n",
        "</h3>\n",
        "      \n",
        "<h7>\n",
        "\n",
        "*   Třeba všechny postupně spustit\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "<h5>\n",
        "\n",
        "\n",
        "\n",
        "1.   Pro start Ollamy\n",
        "2.   Pro start Cloudflared\n",
        "3.   Pro instalaci Modelu z listu\n",
        "\n",
        "</h5>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v7Vm8fkcRo2Z"
      },
      "outputs": [],
      "source": [
        "ollama_thread.start()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j1mmb4C6531v"
      },
      "outputs": [],
      "source": [
        "!sudo cloudflared service install eyJhIjoiNzMxYjNmY2Q5ZTYyZTY2ZjcxYWUzNDI1NDU1NjhjYzciLCJ0IjoiYWE5ZDgwODQtZTk1My00OGJiLWIzYjUtOTc5ZTlhN2U1MDQwIiwicyI6Ik1EQXhOR0V4TW1FdE5UVTJOUzAwWVRFMkxUZzNaVFV0TTJVNU9EUmpZV0pqWkdNNCJ9"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "v4tKZFd1XGKy"
      },
      "outputs": [],
      "source": [
        "install_models()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "L4",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNedRi0jluW5ej+BOTgjub9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}